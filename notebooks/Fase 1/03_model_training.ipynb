{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "C0V8oBCPD2Sk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "from dataclasses import dataclass, asdict\n",
        "from typing import Dict, Tuple, List, Optional, Any\n",
        "from pathlib import Path\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge, LogisticRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor, HistGradientBoostingClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import (mean_squared_error, r2_score, accuracy_score,\n",
        "                              precision_score, recall_score, f1_score,\n",
        "                              confusion_matrix, roc_auc_score)\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.combine import SMOTETomek"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration for the pipeline\n",
        "@dataclass\n",
        "class Config:\n",
        "    test_size: float = 0.20\n",
        "    random_state: int = 42\n",
        "    classification_threshold: float = 0.75\n",
        "    cv_folds: int = 5\n",
        "\n",
        "    # Model hyperparameters\n",
        "    rf_n_estimators: int = 100\n",
        "    rf_max_depth: int = 15\n",
        "    rf_min_samples_leaf: int = 5\n",
        "    gb_learning_rate: float = 0.05\n",
        "    gb_max_depth: int = 5\n",
        "    gb_max_iter: int = 200"
      ],
      "metadata": {
        "id": "UJi1J6JrG_RO"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data processing\n",
        "def prepare_features(df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series]:\n",
        "    cols_to_drop = [c for c in ['shares', 'url'] if c in df.columns]\n",
        "    X = df.drop(columns=cols_to_drop, errors='ignore').copy()\n",
        "    y = df['shares'].copy()\n",
        "\n",
        "    if X.isnull().sum().sum() > 0:\n",
        "        X = X.fillna(X.median())\n",
        "\n",
        "    nunique = X.nunique()\n",
        "    constant_cols = nunique[nunique == 1].index.tolist()\n",
        "    if constant_cols:\n",
        "        X = X.drop(columns=constant_cols)\n",
        "\n",
        "    potential_categorical = [\n",
        "        col for col in X.columns\n",
        "        if X[col].nunique() < 10 and X[col].dtype in ['int64', 'float64']\n",
        "    ]\n",
        "\n",
        "    if potential_categorical:\n",
        "        X = pd.get_dummies(X, columns=potential_categorical, drop_first=True)\n",
        "        X = X.astype(float)\n",
        "\n",
        "    if np.isinf(X.values).any():\n",
        "        X = X.replace([np.inf, -np.inf], np.nan).fillna(X.median())\n",
        "\n",
        "    return X, y\n",
        "\n",
        "\n",
        "def remove_correlated_features(X: pd.DataFrame, threshold: float = 0.95) -> pd.DataFrame:\n",
        "    if X.shape[1] >= 100:\n",
        "        return X\n",
        "\n",
        "    correlation_matrix = X.corr().abs()\n",
        "    upper_triangle = correlation_matrix.where(\n",
        "        np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool)\n",
        "    )\n",
        "\n",
        "    to_drop = [col for col in upper_triangle.columns\n",
        "               if any(upper_triangle[col] > threshold)]\n",
        "\n",
        "    return X.drop(columns=to_drop)\n",
        "\n",
        "\n",
        "def create_targets(y: pd.Series, threshold_percentile: float = 0.75) -> Tuple[pd.Series, pd.Series]:\n",
        "    y_reg = np.log1p(y)\n",
        "    thresh_val = y.quantile(threshold_percentile)\n",
        "    y_class = (y > thresh_val).astype(int)\n",
        "\n",
        "    return y_reg, y_class\n",
        "\n",
        "\n",
        "def safe_qcut_bins(y_series: pd.Series,\n",
        "                   q_candidates: Tuple[int, ...] = (10, 8, 6, 5, 4),\n",
        "                   min_bin_size: int = 30) -> Optional[pd.Series]:\n",
        "    y_series = pd.Series(y_series).astype(float)\n",
        "\n",
        "    for q in q_candidates:\n",
        "        try:\n",
        "            bins = pd.qcut(y_series, q=q, duplicates='drop')\n",
        "            counts = bins.value_counts(dropna=False)\n",
        "            if counts.min() >= min_bin_size and counts.size >= 2:\n",
        "                return bins\n",
        "        except ValueError:\n",
        "            continue\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def split_dataset(X: pd.DataFrame, y_reg: pd.Series, y_class: pd.Series,\n",
        "                  test_size: float, random_state: int) -> Tuple:\n",
        "    y_bins = safe_qcut_bins(y_reg)\n",
        "    stratify_param = y_bins if y_bins is not None else None\n",
        "\n",
        "    return train_test_split(\n",
        "        X, y_reg, y_class,\n",
        "        test_size=test_size,\n",
        "        random_state=random_state,\n",
        "        stratify=stratify_param\n",
        "    )"
      ],
      "metadata": {
        "id": "XA62Qy4u0LrC"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model building\n",
        "class ModelFactory:\n",
        "\n",
        "    def __init__(self, config: Config):\n",
        "        self.config = config\n",
        "\n",
        "    def create_classification_models(self, class_weight: Optional[Dict] = None) -> Dict[str, Any]:\n",
        "        return {\n",
        "            'Logistic Regression': Pipeline([\n",
        "                ('scaler', StandardScaler()),\n",
        "                ('lr', LogisticRegression(\n",
        "                    C=1.0,\n",
        "                    max_iter=1000,\n",
        "                    class_weight=class_weight,\n",
        "                    random_state=self.config.random_state\n",
        "                ))\n",
        "            ]),\n",
        "            'Random Forest': RandomForestClassifier(\n",
        "                n_estimators=self.config.rf_n_estimators,\n",
        "                max_depth=self.config.rf_max_depth,\n",
        "                min_samples_leaf=self.config.rf_min_samples_leaf,\n",
        "                min_samples_split=10,\n",
        "                max_features='sqrt',\n",
        "                class_weight=class_weight or 'balanced',\n",
        "                n_jobs=-1,\n",
        "                random_state=self.config.random_state\n",
        "            ),\n",
        "            'Gradient Boosting': HistGradientBoostingClassifier(\n",
        "                learning_rate=self.config.gb_learning_rate,\n",
        "                max_depth=self.config.gb_max_depth,\n",
        "                max_bins=255,\n",
        "                l2_regularization=1.0,\n",
        "                max_iter=self.config.gb_max_iter,\n",
        "                early_stopping=True,\n",
        "                validation_fraction=0.1,\n",
        "                n_iter_no_change=20,\n",
        "                random_state=self.config.random_state\n",
        "            )\n",
        "        }\n",
        "\n",
        "\n",
        "def train_models(models: Dict[str, Any], X_train, y_train) -> Dict[str, Any]:\n",
        "    trained = {}\n",
        "    for name, model in models.items():\n",
        "        print(f\"Training {name}...\")\n",
        "        model.fit(X_train, y_train)\n",
        "        trained[name] = model\n",
        "    return trained"
      ],
      "metadata": {
        "id": "6d9fITRcHeHy"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "def evaluate_classification(model, X_test, y_test) -> Dict[str, float]:\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    results = {\n",
        "        'accuracy': accuracy_score(y_test, y_pred),\n",
        "        'precision': precision_score(y_test, y_pred, zero_division=0),\n",
        "        'recall': recall_score(y_test, y_pred, zero_division=0),\n",
        "        'f1': f1_score(y_test, y_pred, zero_division=0),\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        results['auc'] = roc_auc_score(y_test, y_pred_proba)\n",
        "    except:\n",
        "        results['auc'] = None\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def find_best_threshold(model, X_test, y_test,\n",
        "                        thresholds: List[float] = [0.3, 0.35, 0.4, 0.45, 0.5]) -> Tuple[float, Dict]:\n",
        "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    best_f1 = 0\n",
        "    best_threshold = 0.5\n",
        "    best_results = {}\n",
        "\n",
        "    for threshold in thresholds:\n",
        "        y_pred = (y_pred_proba >= threshold).astype(int)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_threshold = threshold\n",
        "            best_results = {\n",
        "                'accuracy': accuracy_score(y_test, y_pred),\n",
        "                'precision': precision_score(y_test, y_pred),\n",
        "                'recall': recall_score(y_test, y_pred),\n",
        "                'f1': f1,\n",
        "                'threshold': best_threshold\n",
        "            }\n",
        "\n",
        "    return best_threshold, best_results"
      ],
      "metadata": {
        "id": "dLBCo5tqHp9_"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imbalance handling\n",
        "def apply_smote(X_train, y_train, random_state: int) -> Tuple:\n",
        "    smote = SMOTE(random_state=random_state)\n",
        "    return smote.fit_resample(X_train, y_train)\n",
        "\n",
        "\n",
        "def apply_undersampling(X_train, y_train, random_state: int) -> Tuple:\n",
        "    rus = RandomUnderSampler(random_state=random_state)\n",
        "    return rus.fit_resample(X_train, y_train)\n",
        "\n",
        "\n",
        "def calculate_class_weights(y_train) -> Dict[int, float]:\n",
        "    class_counts = np.bincount(y_train)\n",
        "    total = len(y_train)\n",
        "    return {\n",
        "        0: total / (2 * class_counts[0]),\n",
        "        1: total / (2 * class_counts[1])\n",
        "    }"
      ],
      "metadata": {
        "id": "yK9tzd-HHwns"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model persistence\n",
        "def save_model_to_downloads(model, feature_names: List[str], metadata: Dict):\n",
        "\n",
        "    # File names\n",
        "    model_filename = 'online_news_model.pkl'\n",
        "    metadata_filename = 'model_metadata.pkl'\n",
        "\n",
        "    # Save model\n",
        "    print(f\"\\nSaving model to {model_filename}...\")\n",
        "    with open(model_filename, 'wb') as f:\n",
        "        pickle.dump(model, f)\n",
        "\n",
        "    # Save metadata with feature names\n",
        "    full_metadata = {\n",
        "        'feature_names': feature_names,\n",
        "        'metadata': metadata,\n",
        "        'saved_at': datetime.now().isoformat()\n",
        "    }\n",
        "\n",
        "    print(f\"Saving metadata to {metadata_filename}...\")\n",
        "    with open(metadata_filename, 'wb') as f:\n",
        "        pickle.dump(full_metadata, f)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"Model Saved Succesfully\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Check if running in Colab\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        print(\"\\ndownloading files to your computer...\")\n",
        "        files.download(model_filename)\n",
        "        files.download(metadata_filename)\n",
        "        print(\"Files downloaded to your Downloads folder!\")\n",
        "    except ImportError:\n",
        "        # Not in Colab - just save locally\n",
        "        print(f\"Model saved to: {Path.cwd() / model_filename}\")\n",
        "        print(f\"Metadata saved to: {Path.cwd() / metadata_filename}\")\n",
        "\n",
        "    return model_filename, metadata_filename"
      ],
      "metadata": {
        "id": "jtDPYXq2Lg_B"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main pipeline\n",
        "class MLPipeline:\n",
        "\n",
        "    def __init__(self, config: Config):\n",
        "        self.config = config\n",
        "        self.factory = ModelFactory(config)\n",
        "        self.best_model = None\n",
        "        self.best_model_name = None\n",
        "        self.feature_names = None\n",
        "        self.metadata = {}\n",
        "\n",
        "    def run_baseline(self, df: pd.DataFrame) -> Dict:\n",
        "        print(\"=\" * 60)\n",
        "        print(\"PREPARING DATA\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        X, y = prepare_features(df)\n",
        "        X = remove_correlated_features(X)\n",
        "        y_reg, y_class = create_targets(y, self.config.classification_threshold)\n",
        "\n",
        "        X_train, X_test, y_reg_train, y_reg_test, y_class_train, y_class_test = split_dataset(\n",
        "            X, y_reg, y_class, self.config.test_size, self.config.random_state\n",
        "        )\n",
        "\n",
        "        print(f\"Training set: {len(X_train)} samples\")\n",
        "        print(f\"Test set: {len(X_test)} samples\")\n",
        "        print(f\"Features: {X.shape[1]}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"TRAINING BASELINE MODELS\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        clf_models = self.factory.create_classification_models()\n",
        "        trained_clf = train_models(clf_models, X_train, y_class_train)\n",
        "\n",
        "        clf_results = {}\n",
        "        for name, model in trained_clf.items():\n",
        "            clf_results[name] = evaluate_classification(model, X_test, y_class_test)\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"BASELINE RESULTS\")\n",
        "        print(\"=\" * 60)\n",
        "        for name, metrics in sorted(clf_results.items(), key=lambda x: x[1]['f1'], reverse=True):\n",
        "            print(f\"\\n{name}:\")\n",
        "            print(f\"  F1: {metrics['f1']:.4f} | Recall: {metrics['recall']:.4f} | Precision: {metrics['precision']:.4f}\")\n",
        "\n",
        "        best_name = max(clf_results.items(), key=lambda x: x[1]['f1'])[0]\n",
        "        self.feature_names = X.columns.tolist()\n",
        "\n",
        "        return {\n",
        "            'X_train': X_train, 'X_test': X_test,\n",
        "            'y_class_train': y_class_train, 'y_class_test': y_class_test,\n",
        "            'clf_results': clf_results,\n",
        "            'best_model_name': best_name,\n",
        "            'best_model': trained_clf[best_name],\n",
        "            'trained_models': trained_clf,\n",
        "            'feature_names': self.feature_names\n",
        "        }\n",
        "\n",
        "    def run_with_imbalance_handling(self, X_train, y_train, X_test, y_test) -> Dict:\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"TRAINING WITH IMBALANCE HANDLING\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        all_results = {}\n",
        "        all_models = {}\n",
        "\n",
        "        # SMOTE\n",
        "        print(\"\\n[1/4] SMOTE...\")\n",
        "        X_smote, y_smote = apply_smote(X_train, y_train, self.config.random_state)\n",
        "        smote_models = self.factory.create_classification_models()\n",
        "        trained_smote = train_models(smote_models, X_smote, y_smote)\n",
        "\n",
        "        for name, model in trained_smote.items():\n",
        "            result_name = f'{name} (SMOTE)'\n",
        "            all_results[result_name] = evaluate_classification(model, X_test, y_test)\n",
        "            all_models[result_name] = model\n",
        "\n",
        "        # Undersampling\n",
        "        print(\"\\n[2/4] Undersampling...\")\n",
        "        X_under, y_under = apply_undersampling(X_train, y_train, self.config.random_state)\n",
        "        under_models = self.factory.create_classification_models()\n",
        "        trained_under = train_models(under_models, X_under, y_under)\n",
        "\n",
        "        for name, model in trained_under.items():\n",
        "            result_name = f'{name} (Undersample)'\n",
        "            all_results[result_name] = evaluate_classification(model, X_test, y_test)\n",
        "            all_models[result_name] = model\n",
        "\n",
        "        # Custom weights\n",
        "        print(\"\\n[3/4] Custom Weights...\")\n",
        "        class_weights = calculate_class_weights(y_train)\n",
        "        weight_models = self.factory.create_classification_models(class_weights)\n",
        "        trained_weights = train_models(weight_models, X_train, y_train)\n",
        "\n",
        "        for name, model in trained_weights.items():\n",
        "            result_name = f'{name} (Weighted)'\n",
        "            all_results[result_name] = evaluate_classification(model, X_test, y_test)\n",
        "            all_models[result_name] = model\n",
        "\n",
        "        # Threshold tuning\n",
        "        print(\"\\n[4/4] Threshold Tuning...\")\n",
        "        rf_model = RandomForestClassifier(\n",
        "            n_estimators=self.config.rf_n_estimators,\n",
        "            max_depth=self.config.rf_max_depth,\n",
        "            class_weight='balanced',\n",
        "            random_state=self.config.random_state,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "        rf_model.fit(X_train, y_train)\n",
        "        best_threshold, threshold_results = find_best_threshold(rf_model, X_test, y_test)\n",
        "        result_name = 'Random Forest (Threshold Tuned)'\n",
        "        all_results[result_name] = threshold_results\n",
        "        all_models[result_name] = rf_model\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"IMBALANCE HANDLING RESULTS\")\n",
        "        print(\"=\" * 60)\n",
        "        for name, metrics in sorted(all_results.items(), key=lambda x: x[1]['f1'], reverse=True):\n",
        "            print(f\"\\n{name}:\")\n",
        "            print(f\"  F1: {metrics['f1']:.4f} | Recall: {metrics['recall']:.4f} | Precision: {metrics['precision']:.4f}\")\n",
        "\n",
        "        return {'results': all_results, 'models': all_models}\n",
        "\n",
        "    def train_and_save(self, data_path: str):\n",
        "        print(\"=\" * 60)\n",
        "        print(\"ML PIPELINE - ONLINE NEWS POPULARITY\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # Load data\n",
        "        df = pd.read_csv(data_path)\n",
        "        print(f\"\\nDataset: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
        "\n",
        "        # Run baseline\n",
        "        baseline = self.run_baseline(df)\n",
        "\n",
        "        # Run with imbalance handling\n",
        "        improved = self.run_with_imbalance_handling(\n",
        "            baseline['X_train'],\n",
        "            baseline['y_class_train'],\n",
        "            baseline['X_test'],\n",
        "            baseline['y_class_test']\n",
        "        )\n",
        "\n",
        "        # Select best model\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"FINAL MODEL SELECTION\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        baseline_f1 = baseline['clf_results'][baseline['best_model_name']]['f1']\n",
        "        best_improved_name = max(improved['results'].items(), key=lambda x: x[1]['f1'])[0]\n",
        "        improved_f1 = improved['results'][best_improved_name]['f1']\n",
        "\n",
        "        print(f\"\\nBaseline: {baseline['best_model_name']} - F1: {baseline_f1:.4f}\")\n",
        "        print(f\"Improved: {best_improved_name} - F1: {improved_f1:.4f}\")\n",
        "\n",
        "        if improved_f1 > baseline_f1:\n",
        "            self.best_model = improved['models'][best_improved_name]\n",
        "            self.best_model_name = best_improved_name\n",
        "            best_metrics = improved['results'][best_improved_name]\n",
        "            print(f\"\\nUsing improved model: {best_improved_name}\")\n",
        "        else:\n",
        "            self.best_model = baseline['best_model']\n",
        "            self.best_model_name = baseline['best_model_name']\n",
        "            best_metrics = baseline['clf_results'][baseline['best_model_name']]\n",
        "            print(f\"\\nUsing baseline model: {baseline['best_model_name']}\")\n",
        "\n",
        "        # Prepare metadata\n",
        "        self.metadata = {\n",
        "            'model_name': self.best_model_name,\n",
        "            'f1_score': best_metrics['f1'],\n",
        "            'recall': best_metrics['recall'],\n",
        "            'precision': best_metrics['precision'],\n",
        "            'accuracy': best_metrics['accuracy'],\n",
        "            'classification_threshold': self.config.classification_threshold,\n",
        "            'feature_count': len(self.feature_names),\n",
        "            'training_samples': len(baseline['X_train']),\n",
        "            'test_samples': len(baseline['X_test']),\n",
        "            'config': asdict(self.config)\n",
        "        }\n",
        "\n",
        "        # Save to Downloads folder\n",
        "        save_model_to_downloads(\n",
        "            self.best_model,\n",
        "            self.feature_names,\n",
        "            self.metadata\n",
        "        )\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"Training complete\")\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"\\nBest Model: {self.best_model_name}\")\n",
        "        print(f\"F1-Score: {best_metrics['f1']:.4f}\")\n",
        "        print(f\"Recall: {best_metrics['recall']:.4f}\")\n",
        "        print(f\"Precision: {best_metrics['precision']:.4f}\")\n",
        "        print(f\"Accuracy: {best_metrics['accuracy']:.4f}\")\n",
        "\n",
        "        return self.best_model, self.metadata"
      ],
      "metadata": {
        "id": "h1aYOkauH3wp"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main execution\n",
        "def main():\n",
        "    config = Config()\n",
        "    pipeline = MLPipeline(config)\n",
        "    model, metadata = pipeline.train_and_save('online_news_original.csv')\n",
        "    return model, metadata\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "k6sWXAsLIGw3",
        "outputId": "30bac3d1-ea8d-43f3-d02a-d0c0a4edba65"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "ML PIPELINE - ONLINE NEWS POPULARITY\n",
            "============================================================\n",
            "\n",
            "Dataset: 39644 rows, 61 columns\n",
            "============================================================\n",
            "PREPARING DATA\n",
            "============================================================\n",
            "Training set: 31715 samples\n",
            "Test set: 7929 samples\n",
            "Features: 57\n",
            "\n",
            "============================================================\n",
            "TRAINING BASELINE MODELS\n",
            "============================================================\n",
            "Training Logistic Regression...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "\n",
            "============================================================\n",
            "BASELINE RESULTS\n",
            "============================================================\n",
            "\n",
            "Random Forest:\n",
            "  F1: 0.4358 | Recall: 0.4220 | Precision: 0.4506\n",
            "\n",
            "Gradient Boosting:\n",
            "  F1: 0.2282 | Recall: 0.1420 | Precision: 0.5796\n",
            "\n",
            "Logistic Regression:\n",
            "  F1: 0.1653 | Recall: 0.0978 | Precision: 0.5326\n",
            "\n",
            "============================================================\n",
            "TRAINING WITH IMBALANCE HANDLING\n",
            "============================================================\n",
            "\n",
            "[1/4] SMOTE...\n",
            "Training Logistic Regression...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "\n",
            "[2/4] Undersampling...\n",
            "Training Logistic Regression...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "\n",
            "[3/4] Custom Weights...\n",
            "Training Logistic Regression...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "\n",
            "[4/4] Threshold Tuning...\n",
            "\n",
            "============================================================\n",
            "IMBALANCE HANDLING RESULTS\n",
            "============================================================\n",
            "\n",
            "Random Forest (Undersample):\n",
            "  F1: 0.4826 | Recall: 0.6764 | Precision: 0.3751\n",
            "\n",
            "Gradient Boosting (Undersample):\n",
            "  F1: 0.4825 | Recall: 0.6748 | Precision: 0.3755\n",
            "\n",
            "Random Forest (Threshold Tuned):\n",
            "  F1: 0.4796 | Recall: 0.6712 | Precision: 0.3732\n",
            "\n",
            "Logistic Regression (Weighted):\n",
            "  F1: 0.4643 | Recall: 0.6197 | Precision: 0.3713\n",
            "\n",
            "Logistic Regression (SMOTE):\n",
            "  F1: 0.4623 | Recall: 0.6212 | Precision: 0.3682\n",
            "\n",
            "Logistic Regression (Undersample):\n",
            "  F1: 0.4609 | Recall: 0.6207 | Precision: 0.3665\n",
            "\n",
            "Random Forest (Weighted):\n",
            "  F1: 0.4358 | Recall: 0.4220 | Precision: 0.4506\n",
            "\n",
            "Random Forest (SMOTE):\n",
            "  F1: 0.3216 | Recall: 0.2430 | Precision: 0.4756\n",
            "\n",
            "Gradient Boosting (SMOTE):\n",
            "  F1: 0.2704 | Recall: 0.1816 | Precision: 0.5296\n",
            "\n",
            "Gradient Boosting (Weighted):\n",
            "  F1: 0.2282 | Recall: 0.1420 | Precision: 0.5796\n",
            "\n",
            "============================================================\n",
            "FINAL MODEL SELECTION\n",
            "============================================================\n",
            "\n",
            "Baseline: Random Forest - F1: 0.4358\n",
            "Improved: Random Forest (Undersample) - F1: 0.4826\n",
            "\n",
            "Using improved model: Random Forest (Undersample)\n",
            "\n",
            "Saving model to online_news_model.pkl...\n",
            "Saving metadata to model_metadata.pkl...\n",
            "\n",
            "============================================================\n",
            "Model Saved Succesfully\n",
            "============================================================\n",
            "\n",
            "downloading files to your computer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c4ee7b50-735f-41d6-b48d-fda024d7fb52\", \"online_news_model.pkl\", 15689361)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7bd6693b-05ea-46f4-a5d5-041517b66d4f\", \"model_metadata.pkl\", 1679)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files downloaded to your Downloads folder!\n",
            "\n",
            "============================================================\n",
            "Training complete\n",
            "============================================================\n",
            "\n",
            "Best Model: Random Forest (Undersample)\n",
            "F1-Score: 0.4826\n",
            "Recall: 0.6764\n",
            "Precision: 0.3751\n",
            "Accuracy: 0.6484\n"
          ]
        }
      ]
    }
  ]
}