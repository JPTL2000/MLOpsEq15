{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "C0V8oBCPD2Sk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge, LogisticRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original_news_df = pd.read_csv('online_news_original.csv')\n",
        "original_news_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "XA62Qy4u0LrC",
        "outputId": "83485fa8-1bd9-409c-b24d-dace3e5e5da8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     url  timedelta  \\\n",
              "0      http://mashable.com/2013/01/07/amazon-instant-...      731.0   \n",
              "1      http://mashable.com/2013/01/07/ap-samsung-spon...      731.0   \n",
              "2      http://mashable.com/2013/01/07/apple-40-billio...      731.0   \n",
              "3      http://mashable.com/2013/01/07/astronaut-notre...      731.0   \n",
              "4       http://mashable.com/2013/01/07/att-u-verse-apps/      731.0   \n",
              "...                                                  ...        ...   \n",
              "39639  http://mashable.com/2014/12/27/samsung-app-aut...        8.0   \n",
              "39640  http://mashable.com/2014/12/27/seth-rogen-jame...        8.0   \n",
              "39641  http://mashable.com/2014/12/27/son-pays-off-mo...        8.0   \n",
              "39642     http://mashable.com/2014/12/27/ukraine-blasts/        8.0   \n",
              "39643  http://mashable.com/2014/12/27/youtube-channel...        8.0   \n",
              "\n",
              "       n_tokens_title  n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n",
              "0                12.0             219.0         0.663594               1.0   \n",
              "1                 9.0             255.0         0.604743               1.0   \n",
              "2                 9.0             211.0         0.575130               1.0   \n",
              "3                 9.0             531.0         0.503788               1.0   \n",
              "4                13.0            1072.0         0.415646               1.0   \n",
              "...               ...               ...              ...               ...   \n",
              "39639            11.0             346.0         0.529052               1.0   \n",
              "39640            12.0             328.0         0.696296               1.0   \n",
              "39641            10.0             442.0         0.516355               1.0   \n",
              "39642             6.0             682.0         0.539493               1.0   \n",
              "39643            10.0             157.0         0.701987               1.0   \n",
              "\n",
              "       n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  num_imgs  ...  \\\n",
              "0                      0.815385        4.0             2.0       1.0  ...   \n",
              "1                      0.791946        3.0             1.0       1.0  ...   \n",
              "2                      0.663866        3.0             1.0       1.0  ...   \n",
              "3                      0.665635        9.0             0.0       1.0  ...   \n",
              "4                      0.540890       19.0            19.0      20.0  ...   \n",
              "...                         ...        ...             ...       ...  ...   \n",
              "39639                  0.684783        9.0             7.0       1.0  ...   \n",
              "39640                  0.885057        9.0             7.0       3.0  ...   \n",
              "39641                  0.644128       24.0             1.0      12.0  ...   \n",
              "39642                  0.692661       10.0             1.0       1.0  ...   \n",
              "39643                  0.846154        1.0             1.0       0.0  ...   \n",
              "\n",
              "       min_positive_polarity  max_positive_polarity  avg_negative_polarity  \\\n",
              "0                   0.100000                   0.70              -0.350000   \n",
              "1                   0.033333                   0.70              -0.118750   \n",
              "2                   0.100000                   1.00              -0.466667   \n",
              "3                   0.136364                   0.80              -0.369697   \n",
              "4                   0.033333                   1.00              -0.220192   \n",
              "...                      ...                    ...                    ...   \n",
              "39639               0.100000                   0.75              -0.260000   \n",
              "39640               0.136364                   0.70              -0.211111   \n",
              "39641               0.136364                   0.50              -0.356439   \n",
              "39642               0.062500                   0.50              -0.205246   \n",
              "39643               0.100000                   0.50              -0.200000   \n",
              "\n",
              "       min_negative_polarity  max_negative_polarity  title_subjectivity  \\\n",
              "0                     -0.600              -0.200000            0.500000   \n",
              "1                     -0.125              -0.100000            0.000000   \n",
              "2                     -0.800              -0.133333            0.000000   \n",
              "3                     -0.600              -0.166667            0.000000   \n",
              "4                     -0.500              -0.050000            0.454545   \n",
              "...                      ...                    ...                 ...   \n",
              "39639                 -0.500              -0.125000            0.100000   \n",
              "39640                 -0.400              -0.100000            0.300000   \n",
              "39641                 -0.800              -0.166667            0.454545   \n",
              "39642                 -0.500              -0.012500            0.000000   \n",
              "39643                 -0.200              -0.200000            0.333333   \n",
              "\n",
              "       title_sentiment_polarity  abs_title_subjectivity  \\\n",
              "0                     -0.187500                0.000000   \n",
              "1                      0.000000                0.500000   \n",
              "2                      0.000000                0.500000   \n",
              "3                      0.000000                0.500000   \n",
              "4                      0.136364                0.045455   \n",
              "...                         ...                     ...   \n",
              "39639                  0.000000                0.400000   \n",
              "39640                  1.000000                0.200000   \n",
              "39641                  0.136364                0.045455   \n",
              "39642                  0.000000                0.500000   \n",
              "39643                  0.250000                0.166667   \n",
              "\n",
              "       abs_title_sentiment_polarity  shares  \n",
              "0                          0.187500     593  \n",
              "1                          0.000000     711  \n",
              "2                          0.000000    1500  \n",
              "3                          0.000000    1200  \n",
              "4                          0.136364     505  \n",
              "...                             ...     ...  \n",
              "39639                      0.000000    1800  \n",
              "39640                      1.000000    1900  \n",
              "39641                      0.136364    1900  \n",
              "39642                      0.000000    1100  \n",
              "39643                      0.250000    1300  \n",
              "\n",
              "[39644 rows x 61 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5134dd73-09c9-491b-9c7d-a55434dd5679\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>timedelta</th>\n",
              "      <th>n_tokens_title</th>\n",
              "      <th>n_tokens_content</th>\n",
              "      <th>n_unique_tokens</th>\n",
              "      <th>n_non_stop_words</th>\n",
              "      <th>n_non_stop_unique_tokens</th>\n",
              "      <th>num_hrefs</th>\n",
              "      <th>num_self_hrefs</th>\n",
              "      <th>num_imgs</th>\n",
              "      <th>...</th>\n",
              "      <th>min_positive_polarity</th>\n",
              "      <th>max_positive_polarity</th>\n",
              "      <th>avg_negative_polarity</th>\n",
              "      <th>min_negative_polarity</th>\n",
              "      <th>max_negative_polarity</th>\n",
              "      <th>title_subjectivity</th>\n",
              "      <th>title_sentiment_polarity</th>\n",
              "      <th>abs_title_subjectivity</th>\n",
              "      <th>abs_title_sentiment_polarity</th>\n",
              "      <th>shares</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>http://mashable.com/2013/01/07/amazon-instant-...</td>\n",
              "      <td>731.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>0.663594</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.815385</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.70</td>\n",
              "      <td>-0.350000</td>\n",
              "      <td>-0.600</td>\n",
              "      <td>-0.200000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>-0.187500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>http://mashable.com/2013/01/07/ap-samsung-spon...</td>\n",
              "      <td>731.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>0.604743</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.791946</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.70</td>\n",
              "      <td>-0.118750</td>\n",
              "      <td>-0.125</td>\n",
              "      <td>-0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>http://mashable.com/2013/01/07/apple-40-billio...</td>\n",
              "      <td>731.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>211.0</td>\n",
              "      <td>0.575130</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.663866</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>-0.466667</td>\n",
              "      <td>-0.800</td>\n",
              "      <td>-0.133333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>http://mashable.com/2013/01/07/astronaut-notre...</td>\n",
              "      <td>731.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>531.0</td>\n",
              "      <td>0.503788</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.665635</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.80</td>\n",
              "      <td>-0.369697</td>\n",
              "      <td>-0.600</td>\n",
              "      <td>-0.166667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>http://mashable.com/2013/01/07/att-u-verse-apps/</td>\n",
              "      <td>731.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1072.0</td>\n",
              "      <td>0.415646</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.540890</td>\n",
              "      <td>19.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>1.00</td>\n",
              "      <td>-0.220192</td>\n",
              "      <td>-0.500</td>\n",
              "      <td>-0.050000</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39639</th>\n",
              "      <td>http://mashable.com/2014/12/27/samsung-app-aut...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>346.0</td>\n",
              "      <td>0.529052</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.684783</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.75</td>\n",
              "      <td>-0.260000</td>\n",
              "      <td>-0.500</td>\n",
              "      <td>-0.125000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39640</th>\n",
              "      <td>http://mashable.com/2014/12/27/seth-rogen-jame...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>328.0</td>\n",
              "      <td>0.696296</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.885057</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.70</td>\n",
              "      <td>-0.211111</td>\n",
              "      <td>-0.400</td>\n",
              "      <td>-0.100000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39641</th>\n",
              "      <td>http://mashable.com/2014/12/27/son-pays-off-mo...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>442.0</td>\n",
              "      <td>0.516355</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.644128</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.50</td>\n",
              "      <td>-0.356439</td>\n",
              "      <td>-0.800</td>\n",
              "      <td>-0.166667</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>1900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39642</th>\n",
              "      <td>http://mashable.com/2014/12/27/ukraine-blasts/</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>682.0</td>\n",
              "      <td>0.539493</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.692661</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.50</td>\n",
              "      <td>-0.205246</td>\n",
              "      <td>-0.500</td>\n",
              "      <td>-0.012500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39643</th>\n",
              "      <td>http://mashable.com/2014/12/27/youtube-channel...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>157.0</td>\n",
              "      <td>0.701987</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.50</td>\n",
              "      <td>-0.200000</td>\n",
              "      <td>-0.200</td>\n",
              "      <td>-0.200000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>1300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>39644 rows × 61 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5134dd73-09c9-491b-9c7d-a55434dd5679')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5134dd73-09c9-491b-9c7d-a55434dd5679 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5134dd73-09c9-491b-9c7d-a55434dd5679');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-63ece5ee-585f-45dc-9e3b-4ad16446e817\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-63ece5ee-585f-45dc-9e3b-4ad16446e817')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-63ece5ee-585f-45dc-9e3b-4ad16446e817 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_6a4376b5-a579-4ec4-a9c7-823eb8023631\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('original_news_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6a4376b5-a579-4ec4-a9c7-823eb8023631 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('original_news_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "original_news_df"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_SIZE = 0.20\n",
        "RANDOM_STATE = 42\n",
        "CLASSIFICATION_THRESHOLD = 0.75"
      ],
      "metadata": {
        "id": "I_jloG3O05LG"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rmse(y_true, y_pred):\n",
        "    try:\n",
        "        return mean_squared_error(y_true, y_pred, squared=False)\n",
        "    except TypeError:\n",
        "        return np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "\n",
        "def safe_qcut_bins(y_series, q_candidates=(10, 8, 6, 5, 4), min_bin_size=30):\n",
        "    y_series = pd.Series(y_series).astype(float)\n",
        "    for q in q_candidates:\n",
        "        try:\n",
        "            bins = pd.qcut(y_series, q=q, duplicates='drop')\n",
        "            counts = bins.value_counts(dropna=False)\n",
        "            if counts.min() >= min_bin_size and counts.size >= 2:\n",
        "                return bins\n",
        "        except ValueError:\n",
        "            continue\n",
        "    return None\n",
        "\n",
        "\n",
        "def explore_data(df):\n",
        "    print(\"=\" * 60)\n",
        "    print(\"DATA EXPLORATION\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    print(f\"\\nDataset shape: {df.shape}\")\n",
        "    print(f\"Missing values: {df.isnull().sum().sum()}\")\n",
        "\n",
        "    if 'shares' in df.columns:\n",
        "        print(f\"\\nTarget Statistics:\")\n",
        "        print(f\"  Mean: {df['shares'].mean():.2f}\")\n",
        "        print(f\"  Median: {df['shares'].median():.2f}\")\n",
        "        print(f\"  Std: {df['shares'].std():.2f}\")\n",
        "        print(f\"  Min: {df['shares'].min():.2f}\")\n",
        "        print(f\"  Max: {df['shares'].max():.2f}\")\n",
        "\n",
        "\n",
        "def prepare_features(df):\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"DATA PREPARATION\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Drop target and non-features\n",
        "    cols_to_drop = [c for c in ['shares', 'url'] if c in df.columns]\n",
        "    X = df.drop(columns=cols_to_drop, errors='ignore')\n",
        "    y = df['shares'].copy()\n",
        "\n",
        "    # Handle missing values\n",
        "    if X.isnull().sum().sum() > 0:\n",
        "        X = X.fillna(X.median())\n",
        "\n",
        "    # Remove constant columns\n",
        "    nunique = X.nunique()\n",
        "    constant_cols = nunique[nunique == 1].index.tolist()\n",
        "    if constant_cols:\n",
        "        X = X.drop(columns=constant_cols)\n",
        "\n",
        "    # One-hot encode potential categorical features\n",
        "    potential_categorical = [col for col in X.columns\n",
        "                             if X[col].nunique() < 10 and X[col].dtype in ['int64', 'float64']]\n",
        "\n",
        "    if potential_categorical:\n",
        "        X = pd.get_dummies(X, columns=potential_categorical, drop_first=True)\n",
        "        X = X.astype(float)\n",
        "\n",
        "    # Handle infinite values\n",
        "    if np.isinf(X.values).any():\n",
        "        X = X.replace([np.inf, -np.inf], np.nan).fillna(X.median())\n",
        "\n",
        "    print(f\"Final feature matrix: {X.shape}\")\n",
        "\n",
        "    return X, y\n",
        "\n",
        "\n",
        "def analyze_feature_correlation(X):\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"FEATURE CORRELATION ANALYSIS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    if X.shape[1] < 100:\n",
        "        correlation_matrix = X.corr().abs()\n",
        "        upper_triangle = correlation_matrix.where(\n",
        "            np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool)\n",
        "        )\n",
        "        high_corr_features = [col for col in upper_triangle.columns\n",
        "                              if any(upper_triangle[col] > 0.95)]\n",
        "\n",
        "        if high_corr_features:\n",
        "            print(f\"Removing {len(high_corr_features)} highly correlated features\")\n",
        "            X = X.drop(columns=high_corr_features)\n",
        "            print(f\"Final features: {X.shape[1]}\")\n",
        "\n",
        "    return X\n",
        "\n",
        "\n",
        "def prepare_targets(y, threshold=CLASSIFICATION_THRESHOLD):\n",
        "    # Regression target (log transform)\n",
        "    if y.mean() < 0.1 and abs(y.std() - 1.0) < 0.1:\n",
        "        y_reg = y.copy()\n",
        "    else:\n",
        "        y_reg = np.log1p(y)\n",
        "\n",
        "    # Classification target\n",
        "    thresh_val = y.quantile(threshold)\n",
        "    y_class = (y > thresh_val).astype(int)\n",
        "\n",
        "    print(f\"\\nClassification Target (Top {int((1-threshold)*100)}%):\")\n",
        "    print(f\"  Low shares:  {(y_class == 0).sum()} ({(y_class == 0).sum()/len(y_class)*100:.1f}%)\")\n",
        "    print(f\"  High shares: {(y_class == 1).sum()} ({(y_class == 1).sum()/len(y_class)*100:.1f}%)\")\n",
        "\n",
        "    return y_reg, y_class\n",
        "\n",
        "# Split data into training and testing sets\n",
        "def split_data(X, y_reg, y_class, test_size=TEST_SIZE, random_state=RANDOM_STATE):\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"TRAIN/TEST SPLIT\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Create bins for stratification\n",
        "    y_bins = safe_qcut_bins(y_reg, q_candidates=(10, 8, 6, 5, 4), min_bin_size=30)\n",
        "    stratify_param = y_bins if y_bins is not None else None\n",
        "\n",
        "    X_train, X_test, y_reg_train, y_reg_test, y_class_train, y_class_test = train_test_split(\n",
        "        X, y_reg, y_class,\n",
        "        test_size=test_size,\n",
        "        random_state=random_state,\n",
        "        stratify=stratify_param\n",
        "    )\n",
        "\n",
        "    print(f\"Training: {len(X_train)} samples ({len(X_train)/len(X)*100:.1f}%)\")\n",
        "    print(f\"Testing:  {len(X_test)} samples ({len(X_test)/len(X)*100:.1f}%)\")\n",
        "\n",
        "    return X_train, X_test, y_reg_train, y_reg_test, y_class_train, y_class_test\n",
        "\n",
        "# Regression models\n",
        "def train_regression_models(X_train, y_reg_train):\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"REGRESSION MODELS\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    models = {}\n",
        "\n",
        "    # Ridge Regression\n",
        "    print(\"\\nTraining Ridge Regression...\")\n",
        "    pipe_ridge = Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"ridge\", Ridge(alpha=1.0, random_state=RANDOM_STATE))\n",
        "    ])\n",
        "    pipe_ridge.fit(X_train, y_reg_train)\n",
        "    models['Ridge'] = pipe_ridge\n",
        "\n",
        "    # Random Forest\n",
        "    print(\"Training Random Forest Regressor...\")\n",
        "    rf_reg = RandomForestRegressor(\n",
        "        n_estimators=100, max_depth=15, min_samples_leaf=5,\n",
        "        min_samples_split=10, max_features='sqrt', max_samples=0.8,\n",
        "        n_jobs=-1, random_state=RANDOM_STATE\n",
        "    )\n",
        "    rf_reg.fit(X_train, y_reg_train)\n",
        "    models['Random Forest'] = rf_reg\n",
        "\n",
        "    # Gradient Boosting\n",
        "    print(\"Training Gradient Boosting Regressor...\")\n",
        "    gb_reg = HistGradientBoostingRegressor(\n",
        "        learning_rate=0.05, max_depth=5, max_bins=255,\n",
        "        l2_regularization=1.0, max_iter=200, early_stopping=True,\n",
        "        validation_fraction=0.1, n_iter_no_change=20, random_state=RANDOM_STATE\n",
        "    )\n",
        "    gb_reg.fit(X_train, y_reg_train)\n",
        "    models['Gradient Boosting'] = gb_reg\n",
        "\n",
        "    return models\n",
        "\n",
        "# Classification models\n",
        "def train_classification_models(X_train, y_class_train):\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"CLASSIFICATION MODELS\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    models = {}\n",
        "\n",
        "    # Logistic Regression\n",
        "    print(\"\\nTraining Logistic Regression...\")\n",
        "    pipe_lr = Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"lr\", LogisticRegression(C=1.0, max_iter=1000, random_state=RANDOM_STATE))\n",
        "    ])\n",
        "    pipe_lr.fit(X_train, y_class_train)\n",
        "    models['Logistic Regression'] = pipe_lr\n",
        "\n",
        "    # Random Forest\n",
        "    print(\"Training Random Forest Classifier...\")\n",
        "    rf_clf = RandomForestClassifier(\n",
        "        n_estimators=100, max_depth=15, min_samples_leaf=5,\n",
        "        min_samples_split=10, max_features='sqrt', class_weight='balanced',\n",
        "        n_jobs=-1, random_state=RANDOM_STATE\n",
        "    )\n",
        "    rf_clf.fit(X_train, y_class_train)\n",
        "    models['Random Forest'] = rf_clf\n",
        "\n",
        "    # Gradient Boosting\n",
        "    print(\"Training Gradient Boosting Classifier...\")\n",
        "    gb_clf = HistGradientBoostingClassifier(\n",
        "        learning_rate=0.05, max_depth=5, max_bins=255,\n",
        "        l2_regularization=1.0, max_iter=200, early_stopping=True,\n",
        "        validation_fraction=0.1, n_iter_no_change=20, random_state=RANDOM_STATE\n",
        "    )\n",
        "    gb_clf.fit(X_train, y_class_train)\n",
        "    models['Gradient Boosting'] = gb_clf\n",
        "\n",
        "    return models\n",
        "\n",
        "# Evaluation\n",
        "def evaluate_regression_model(model, X_test, y_reg_test, model_name):\n",
        "    y_pred = model.predict(X_test)\n",
        "    rmse_val = rmse(y_reg_test, y_pred)\n",
        "    r2_val = r2_score(y_reg_test, y_pred)\n",
        "\n",
        "    print(f\"\\n{model_name}\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"RMSE: {rmse_val:.4f} | R²: {r2_val:.4f}\")\n",
        "\n",
        "    return {'rmse': rmse_val, 'r2': r2_val, 'predictions': y_pred}\n",
        "\n",
        "\n",
        "def evaluate_classification_model(model, X_test, y_class_test, model_name):\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    accuracy = accuracy_score(y_class_test, y_pred)\n",
        "    precision = precision_score(y_class_test, y_pred)\n",
        "    recall = recall_score(y_class_test, y_pred)\n",
        "    f1 = f1_score(y_class_test, y_pred)\n",
        "\n",
        "    try:\n",
        "        auc = roc_auc_score(y_class_test, y_pred_proba)\n",
        "    except:\n",
        "        auc = None\n",
        "\n",
        "    print(f\"\\n{model_name}\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall:    {recall:.4f}\")\n",
        "    print(f\"F1-Score:  {f1:.4f}\")\n",
        "    if auc:\n",
        "        print(f\"ROC-AUC:   {auc:.4f}\")\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy, 'precision': precision, 'recall': recall,\n",
        "        'f1': f1, 'auc': auc, 'predictions': y_pred, 'probabilities': y_pred_proba\n",
        "    }\n",
        "\n",
        "\n",
        "def compare_regression_models(results):\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"REGRESSION MODEL COMPARISON\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    comparison = {name: res['r2'] for name, res in results.items()}\n",
        "    for name, r2 in sorted(comparison.items(), key=lambda x: x[1], reverse=True):\n",
        "        print(f\"{name:25s}: R² = {r2:.4f}\")\n",
        "\n",
        "\n",
        "def compare_classification_models(results):\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"CLASSIFICATION MODEL COMPARISON\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    for name, res in sorted(results.items(), key=lambda x: x[1]['f1'], reverse=True):\n",
        "        print(f\"{name:25s}: F1={res['f1']:.4f}, Acc={res['accuracy']:.4f}\")\n",
        "\n",
        "    best_model = max(results.items(), key=lambda x: x[1]['f1'])\n",
        "    print(f\"\\nBest Classification Model: {best_model[0]}\")\n",
        "    return best_model[0], best_model[1]\n",
        "\n",
        "\n",
        "def show_confusion_matrix(y_true, y_pred, model_name):\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(f\"CONFUSION MATRIX - {model_name}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print(\"\\n                Predicted\")\n",
        "    print(\"              Low    High\")\n",
        "    print(f\"Actual Low   {cm[0,0]:5d}  {cm[0,1]:5d}\")\n",
        "    print(f\"      High   {cm[1,0]:5d}  {cm[1,1]:5d}\")\n",
        "\n",
        "\n",
        "def show_feature_importance(model, feature_names, model_name, top_n=15):\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(f\"TOP {top_n} IMPORTANT FEATURES - {model_name}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    if hasattr(model, 'feature_importances_'):\n",
        "        importances = model.feature_importances_\n",
        "    elif hasattr(model, 'named_steps') and hasattr(model.named_steps['lr'], 'coef_'):\n",
        "        importances = np.abs(model.named_steps['lr'].coef_[0])\n",
        "    else:\n",
        "        print(\"Model does not support feature importance\")\n",
        "        return\n",
        "\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'feature': feature_names,\n",
        "        'importance': importances\n",
        "    }).sort_values('importance', ascending=False)\n",
        "\n",
        "    for idx, row in feature_importance.head(top_n).iterrows():\n",
        "        print(f\"{row['feature']:40s}: {row['importance']:.4f}\")\n",
        "\n",
        "\n",
        "def cross_validate_model(model, X, y, cv=5):\n",
        "    scores = cross_val_score(model, X, y, cv=cv, scoring='f1')\n",
        "    print(f\"\\nCross-Validation F1 Scores: {scores}\")\n",
        "    print(f\"Average F1 with {cv}-Fold CV: {np.mean(scores):.4f} (+/- {np.std(scores):.4f})\")"
      ],
      "metadata": {
        "id": "z1cmL7Zl1UHR"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main function\n",
        "def main(df):\n",
        "    # 1. Explore data\n",
        "    explore_data(df)\n",
        "\n",
        "    # 2. Prepare features\n",
        "    X, y = prepare_features(df)\n",
        "\n",
        "    # 3. Analyze correlations\n",
        "    X = analyze_feature_correlation(X)\n",
        "\n",
        "    # 4. Prepare targets\n",
        "    y_reg, y_class = prepare_targets(y)\n",
        "\n",
        "    # 5. Split data\n",
        "    X_train, X_test, y_reg_train, y_reg_test, y_class_train, y_class_test = split_data(\n",
        "        X, y_reg, y_class\n",
        "    )\n",
        "\n",
        "    # 6. Train and evaluate regression models\n",
        "    reg_models = train_regression_models(X_train, y_reg_train)\n",
        "    reg_results = {}\n",
        "    for name, model in reg_models.items():\n",
        "        reg_results[name] = evaluate_regression_model(model, X_test, y_reg_test, name)\n",
        "    compare_regression_models(reg_results)\n",
        "\n",
        "    # 7. Train and evaluate classification models\n",
        "    clf_models = train_classification_models(X_train, y_class_train)\n",
        "    clf_results = {}\n",
        "    for name, model in clf_models.items():\n",
        "        clf_results[name] = evaluate_classification_model(model, X_test, y_class_test, name)\n",
        "    best_clf_name, best_clf_result = compare_classification_models(clf_results)\n",
        "\n",
        "    # 8. Show confusion matrix for best model\n",
        "    show_confusion_matrix(y_class_test, best_clf_result['predictions'], best_clf_name)\n",
        "\n",
        "    # 9. Show feature importance\n",
        "    show_feature_importance(clf_models[best_clf_name], X.columns, best_clf_name)\n",
        "\n",
        "    # 10. Cross-validate best model\n",
        "    cross_validate_model(clf_models[best_clf_name], X_train, y_class_train, cv=5)\n",
        "\n",
        "    return {\n",
        "      'X_train': X_train, 'X_test': X_test,\n",
        "      'y_class_train': y_class_train, 'y_class_test': y_class_test,\n",
        "      'reg_models': reg_models, 'clf_models': clf_models,\n",
        "      'clf_results': clf_results,\n",
        "      'best_clf_name': best_clf_name,\n",
        "      'best_clf_result': best_clf_result,\n",
        "      'feature_names': X.columns\n",
        "    }"
      ],
      "metadata": {
        "id": "oeQO-oDH15AD"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Target Variable\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.combine import SMOTETomek\n",
        "\n",
        "## SMOTE to handle imbalance\n",
        "def train_with_smote(X_train, y_class_train):\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"TRAINING WITH SMOTE (OVERSAMPLING)\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Apply SMOTE\n",
        "    print(\"\\nApplying SMOTE...\")\n",
        "    smote = SMOTE(random_state=RANDOM_STATE)\n",
        "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_class_train)\n",
        "\n",
        "    print(f\"Original distribution: {np.bincount(y_class_train)}\")\n",
        "    print(f\"After SMOTE: {np.bincount(y_train_smote)}\")\n",
        "\n",
        "    models = {}\n",
        "\n",
        "    # Logistic Regression with SMOTE\n",
        "    print(\"\\nTraining Logistic Regression with SMOTE...\")\n",
        "    pipe_lr = Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"lr\", LogisticRegression(C=1.0, max_iter=1000, random_state=RANDOM_STATE))\n",
        "    ])\n",
        "    pipe_lr.fit(X_train_smote, y_train_smote)\n",
        "    models['Logistic Regression (SMOTE)'] = pipe_lr\n",
        "\n",
        "    # Random Forest with SMOTE\n",
        "    print(\"Training Random Forest with SMOTE...\")\n",
        "    rf_clf = RandomForestClassifier(\n",
        "        n_estimators=100, max_depth=15, min_samples_leaf=5,\n",
        "        min_samples_split=10, max_features='sqrt',\n",
        "        n_jobs=-1, random_state=RANDOM_STATE\n",
        "    )\n",
        "    rf_clf.fit(X_train_smote, y_train_smote)\n",
        "    models['Random Forest (SMOTE)'] = rf_clf\n",
        "\n",
        "    # Gradient Boosting with SMOTE\n",
        "    print(\"Training Gradient Boosting with SMOTE...\")\n",
        "    gb_clf = HistGradientBoostingClassifier(\n",
        "        learning_rate=0.05, max_depth=5, max_bins=255,\n",
        "        l2_regularization=1.0, max_iter=200, random_state=RANDOM_STATE\n",
        "    )\n",
        "    gb_clf.fit(X_train_smote, y_train_smote)\n",
        "    models['Gradient Boosting (SMOTE)'] = gb_clf\n",
        "\n",
        "    return models\n",
        "\n",
        "\n",
        "def train_with_undersampling(X_train, y_class_train):\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"TRAINING WITH RANDOM UNDERSAMPLING\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Apply Random Undersampling\n",
        "    print(\"\\nApplying Random Undersampling...\")\n",
        "    rus = RandomUnderSampler(random_state=RANDOM_STATE)\n",
        "    X_train_rus, y_train_rus = rus.fit_resample(X_train, y_class_train)\n",
        "\n",
        "    print(f\"Original distribution: {np.bincount(y_class_train)}\")\n",
        "    print(f\"After undersampling: {np.bincount(y_train_rus)}\")\n",
        "\n",
        "    models = {}\n",
        "\n",
        "    # Random Forest with undersampling\n",
        "    print(\"\\nTraining Random Forest with undersampling...\")\n",
        "    rf_clf = RandomForestClassifier(\n",
        "        n_estimators=100, max_depth=15, min_samples_leaf=5,\n",
        "        min_samples_split=10, max_features='sqrt',\n",
        "        n_jobs=-1, random_state=RANDOM_STATE\n",
        "    )\n",
        "    rf_clf.fit(X_train_rus, y_train_rus)\n",
        "    models['Random Forest (Undersample)'] = rf_clf\n",
        "\n",
        "    return models\n",
        "\n",
        "\n",
        "def train_with_combined_sampling(X_train, y_class_train):\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"TRAINING WITH SMOTE + TOMEK LINKS\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Apply SMOTETomek\n",
        "    print(\"\\nApplying SMOTETomek...\")\n",
        "    smt = SMOTETomek(random_state=RANDOM_STATE)\n",
        "    X_train_smt, y_train_smt = smt.fit_resample(X_train, y_class_train)\n",
        "\n",
        "    print(f\"Original distribution: {np.bincount(y_class_train)}\")\n",
        "    print(f\"After SMOTETomek: {np.bincount(y_train_smt)}\")\n",
        "\n",
        "    models = {}\n",
        "\n",
        "    # Random Forest with SMOTETomek\n",
        "    print(\"\\nTraining Random Forest with SMOTETomek...\")\n",
        "    rf_clf = RandomForestClassifier(\n",
        "        n_estimators=100, max_depth=15, min_samples_leaf=5,\n",
        "        min_samples_split=10, max_features='sqrt',\n",
        "        n_jobs=-1, random_state=RANDOM_STATE\n",
        "    )\n",
        "    rf_clf.fit(X_train_smt, y_train_smt)\n",
        "    models['Random Forest (SMOTETomek)'] = rf_clf\n",
        "\n",
        "    return models\n",
        "\n",
        "\n",
        "def train_with_adjusted_weights(X_train, y_class_train):\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"TRAINING WITH ADJUSTED CLASS WEIGHTS\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    models = {}\n",
        "\n",
        "    # class weights\n",
        "    class_counts = np.bincount(y_class_train)\n",
        "    total = len(y_class_train)\n",
        "    weight_for_0 = total / (2 * class_counts[0])\n",
        "    weight_for_1 = total / (2 * class_counts[1])\n",
        "\n",
        "    print(f\"\\nClass weights: {{0: {weight_for_0:.2f}, 1: {weight_for_1:.2f}}}\")\n",
        "\n",
        "    # Logistic Regression with custom weights\n",
        "    print(\"\\nTraining Logistic Regression with custom weights...\")\n",
        "    pipe_lr = Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"lr\", LogisticRegression(\n",
        "            C=1.0, max_iter=1000,\n",
        "            class_weight={0: weight_for_0, 1: weight_for_1},\n",
        "            random_state=RANDOM_STATE\n",
        "        ))\n",
        "    ])\n",
        "    pipe_lr.fit(X_train, y_class_train)\n",
        "    models['Logistic Regression (Custom Weights)'] = pipe_lr\n",
        "\n",
        "    # Random Forest with more aggressive weights\n",
        "    print(\"Training Random Forest with custom weights...\")\n",
        "    rf_clf = RandomForestClassifier(\n",
        "        n_estimators=100, max_depth=15, min_samples_leaf=5,\n",
        "        min_samples_split=10, max_features='sqrt',\n",
        "        class_weight={0: weight_for_0, 1: weight_for_1 * 1.5},\n",
        "        n_jobs=-1, random_state=RANDOM_STATE\n",
        "    )\n",
        "    rf_clf.fit(X_train, y_class_train)\n",
        "    models['Random Forest (Custom Weights)'] = rf_clf\n",
        "\n",
        "    return models\n",
        "\n",
        "\n",
        "def train_with_threshold_tuning(X_train, y_class_train):\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"TRAINING WITH THRESHOLD TUNING\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Train standard Random Forest\n",
        "    rf_clf = RandomForestClassifier(\n",
        "        n_estimators=100, max_depth=15, min_samples_leaf=5,\n",
        "        min_samples_split=10, max_features='sqrt', class_weight='balanced',\n",
        "        n_jobs=-1, random_state=RANDOM_STATE\n",
        "    )\n",
        "    rf_clf.fit(X_train, y_class_train)\n",
        "\n",
        "    return {'Random Forest (Threshold Tuning)': rf_clf}\n",
        "\n",
        "\n",
        "def evaluate_with_threshold(model, X_test, y_class_test, thresholds=[0.3, 0.35, 0.4, 0.45, 0.5]):\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"THRESHOLD TUNING RESULTS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    best_f1 = 0\n",
        "    best_threshold = 0.5\n",
        "    best_results = None\n",
        "\n",
        "    for threshold in thresholds:\n",
        "        y_pred = (y_pred_proba >= threshold).astype(int)\n",
        "\n",
        "        f1 = f1_score(y_class_test, y_pred)\n",
        "        precision = precision_score(y_class_test, y_pred)\n",
        "        recall = recall_score(y_class_test, y_pred)\n",
        "        accuracy = accuracy_score(y_class_test, y_pred)\n",
        "\n",
        "        print(f\"\\nThreshold: {threshold:.2f}\")\n",
        "        print(f\"  F1:        {f1:.4f}\")\n",
        "        print(f\"  Precision: {precision:.4f}\")\n",
        "        print(f\"  Recall:    {recall:.4f}\")\n",
        "        print(f\"  Accuracy:  {accuracy:.4f}\")\n",
        "\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_threshold = threshold\n",
        "            best_results = {\n",
        "                'accuracy': accuracy, 'precision': precision,\n",
        "                'recall': recall, 'f1': f1, 'auc': None,\n",
        "                'predictions': y_pred, 'probabilities': y_pred_proba\n",
        "            }\n",
        "\n",
        "    print(f\"\\n*** Best threshold: {best_threshold:.2f} with F1: {best_f1:.4f} ***\")\n",
        "\n",
        "    # Show confusion matrix for best threshold\n",
        "    y_pred_best = (y_pred_proba >= best_threshold).astype(int)\n",
        "    cm = confusion_matrix(y_class_test, y_pred_best)\n",
        "    print(f\"\\nConfusion Matrix (threshold={best_threshold}):\")\n",
        "    print(\"                Predicted\")\n",
        "    print(\"              Low    High\")\n",
        "    print(f\"Actual Low   {cm[0,0]:5d}  {cm[0,1]:5d}\")\n",
        "    print(f\"      High   {cm[1,0]:5d}  {cm[1,1]:5d}\")\n",
        "\n",
        "    return best_results\n",
        "\n",
        "\n",
        "def compare_all_approaches(X_train, X_test, y_class_train, y_class_test):\n",
        "    \"\"\"Compare all imbalance handling approaches\"\"\"\n",
        "    all_results = {}\n",
        "\n",
        "    # 1. SMOTE\n",
        "    smote_models = train_with_smote(X_train, y_class_train)\n",
        "    for name, model in smote_models.items():\n",
        "        all_results[name] = evaluate_classification_model(model, X_test, y_class_test, name)\n",
        "\n",
        "    # 2. Undersampling\n",
        "    under_models = train_with_undersampling(X_train, y_class_train)\n",
        "    for name, model in under_models.items():\n",
        "        all_results[name] = evaluate_classification_model(model, X_test, y_class_test, name)\n",
        "\n",
        "    # 3. SMOTETomek\n",
        "    combined_models = train_with_combined_sampling(X_train, y_class_train)\n",
        "    for name, model in combined_models.items():\n",
        "        all_results[name] = evaluate_classification_model(model, X_test, y_class_test, name)\n",
        "\n",
        "    # 4. Custom Weights\n",
        "    weight_models = train_with_adjusted_weights(X_train, y_class_train)\n",
        "    for name, model in weight_models.items():\n",
        "        all_results[name] = evaluate_classification_model(model, X_test, y_class_test, name)\n",
        "\n",
        "    # 5. Threshold Tuning\n",
        "    threshold_models = train_with_threshold_tuning(X_train, y_class_train)\n",
        "    for name, model in threshold_models.items():\n",
        "        result = evaluate_with_threshold(model, X_test, y_class_test)\n",
        "        all_results[name] = result\n",
        "\n",
        "    # Comparison\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"FINAL COMPARISON - ALL STRATEGIES\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    for name, res in sorted(all_results.items(), key=lambda x: x[1]['f1'], reverse=True):\n",
        "        print(f\"{name:40s}: F1={res['f1']:.4f}, Recall={res['recall']:.4f}, Precision={res['precision']:.4f}\")\n",
        "\n",
        "    best_model = max(all_results.items(), key=lambda x: x[1]['f1'])\n",
        "    print(f\"\\n*** BEST MODEL: {best_model[0]} with F1={best_model[1]['f1']:.4f} ***\")\n",
        "\n",
        "    return all_results"
      ],
      "metadata": {
        "id": "loOO39RO3ZG_"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imbalanced-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jg0rgcFt5Z3L",
        "outputId": "69f04b2b-23fa-4b20-d454-ad6712513e6d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.12/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.6.1)\n",
            "Requirement already satisfied: joblib<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\\n\" + \"=\" * 80)\n",
        "print(\"PART 1: BASELINE MODELS\")\n",
        "print(\"=\" * 80 + \"\\n\")\n",
        "\n",
        "results_1 = main(original_news_df.copy())\n",
        "\n",
        "# Extract variables for Part 2\n",
        "X_train = results_1['X_train']\n",
        "X_test = results_1['X_test']\n",
        "y_class_train = results_1['y_class_train']\n",
        "y_class_test = results_1['y_class_test']\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"PART 1 SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Best Baseline Model: {results_1['best_clf_name']}\")\n",
        "print(f\"  F1-Score:  {results_1['best_clf_result']['f1']:.4f}\")\n",
        "print(f\"  Recall:    {results_1['best_clf_result']['recall']:.4f}\")\n",
        "print(f\"  Precision: {results_1['best_clf_result']['precision']:.4f}\")\n",
        "print(f\"  Accuracy:  {results_1['best_clf_result']['accuracy']:.4f}\")\n",
        "\n",
        "\n",
        "# STEP 3: Run PART 2 - Imbalance Handling\n",
        "print(\"\\n\\n\" + \"=\" * 80)\n",
        "print(\"PART 2: IMBALANCE HANDLING TECHNIQUES\")\n",
        "print(\"=\" * 80 + \"\\n\")\n",
        "\n",
        "results_2 = compare_all_approaches(X_train, X_test, y_class_train, y_class_test)\n",
        "\n",
        "\n",
        "# STEP 4: Final Comparison - Baseline vs Improved\n",
        "print(\"\\n\\n\" + \"=\" * 80)\n",
        "print(\"FINAL COMPARISON: BASELINE vs IMPROVED\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "baseline_f1 = results_1['best_clf_result']['f1']\n",
        "baseline_recall = results_1['best_clf_result']['recall']\n",
        "\n",
        "print(f\"\\nBASELINE ({results_1['best_clf_name']}):\")\n",
        "print(f\"  F1-Score:  {baseline_f1:.4f}\")\n",
        "print(f\"  Recall:    {baseline_recall:.4f}\")\n",
        "\n",
        "best_improved = max(results_2.items(), key=lambda x: x[1]['f1'])\n",
        "improved_f1 = best_improved[1]['f1']\n",
        "improved_recall = best_improved[1]['recall']\n",
        "\n",
        "print(f\"\\nBEST IMPROVED ({best_improved[0]}):\")\n",
        "print(f\"  F1-Score:  {improved_f1:.4f}\")\n",
        "print(f\"  Recall:    {improved_recall:.4f}\")\n",
        "\n",
        "f1_improvement = (improved_f1 - baseline_f1) / baseline_f1 * 100\n",
        "recall_improvement = (improved_recall - baseline_recall) / baseline_recall * 100\n",
        "\n",
        "print(f\"\\nIMPROVEMENT:\")\n",
        "print(f\"  F1-Score:  {f1_improvement:+.1f}%\")\n",
        "print(f\"  Recall:    {recall_improvement:+.1f}%\")\n",
        "\n",
        "if f1_improvement > 0:\n",
        "    print(f\"\\nSuccessfully improved model performance!\")\n",
        "else:\n",
        "    print(f\"\\nBaseline model performed better. Consider using threshold tuning.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiLWIWKk3qBq",
        "outputId": "51e150a2-093a-4c4b-c4ba-410b882ebe32"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "================================================================================\n",
            "PART 1: BASELINE MODELS\n",
            "================================================================================\n",
            "\n",
            "============================================================\n",
            "DATA EXPLORATION\n",
            "============================================================\n",
            "\n",
            "Dataset shape: (39644, 61)\n",
            "Missing values: 0\n",
            "\n",
            "Target Statistics:\n",
            "  Mean: 3395.38\n",
            "  Median: 1400.00\n",
            "  Std: 11626.95\n",
            "  Min: 1.00\n",
            "  Max: 843300.00\n",
            "\n",
            "============================================================\n",
            "DATA PREPARATION\n",
            "============================================================\n",
            "Final feature matrix: (39644, 59)\n",
            "\n",
            "============================================================\n",
            "FEATURE CORRELATION ANALYSIS\n",
            "============================================================\n",
            "Removing 2 highly correlated features\n",
            "Final features: 57\n",
            "\n",
            "Classification Target (Top 25%):\n",
            "  Low shares:  30014 (75.7%)\n",
            "  High shares: 9630 (24.3%)\n",
            "\n",
            "============================================================\n",
            "TRAIN/TEST SPLIT\n",
            "============================================================\n",
            "Training: 31715 samples (80.0%)\n",
            "Testing:  7929 samples (20.0%)\n",
            "\n",
            "================================================================================\n",
            "REGRESSION MODELS\n",
            "================================================================================\n",
            "\n",
            "Training Ridge Regression...\n",
            "Training Random Forest Regressor...\n",
            "Training Gradient Boosting Regressor...\n",
            "\n",
            "Ridge\n",
            "============================================================\n",
            "RMSE: 0.8806 | R²: 0.1256\n",
            "\n",
            "Random Forest\n",
            "============================================================\n",
            "RMSE: 0.8578 | R²: 0.1703\n",
            "\n",
            "Gradient Boosting\n",
            "============================================================\n",
            "RMSE: 0.8483 | R²: 0.1885\n",
            "\n",
            "============================================================\n",
            "REGRESSION MODEL COMPARISON\n",
            "============================================================\n",
            "Gradient Boosting        : R² = 0.1885\n",
            "Random Forest            : R² = 0.1703\n",
            "Ridge                    : R² = 0.1256\n",
            "\n",
            "================================================================================\n",
            "CLASSIFICATION MODELS\n",
            "================================================================================\n",
            "\n",
            "Training Logistic Regression...\n",
            "Training Random Forest Classifier...\n",
            "Training Gradient Boosting Classifier...\n",
            "\n",
            "Logistic Regression\n",
            "============================================================\n",
            "Accuracy:  0.7605\n",
            "Precision: 0.5326\n",
            "Recall:    0.0978\n",
            "F1-Score:  0.1653\n",
            "ROC-AUC:   0.6891\n",
            "\n",
            "Random Forest\n",
            "============================================================\n",
            "Accuracy:  0.7351\n",
            "Precision: 0.4506\n",
            "Recall:    0.4220\n",
            "F1-Score:  0.4358\n",
            "ROC-AUC:   0.7171\n",
            "\n",
            "Gradient Boosting\n",
            "============================================================\n",
            "Accuracy:  0.7671\n",
            "Precision: 0.5796\n",
            "Recall:    0.1420\n",
            "F1-Score:  0.2282\n",
            "ROC-AUC:   0.7214\n",
            "\n",
            "============================================================\n",
            "CLASSIFICATION MODEL COMPARISON\n",
            "============================================================\n",
            "Random Forest            : F1=0.4358, Acc=0.7351\n",
            "Gradient Boosting        : F1=0.2282, Acc=0.7671\n",
            "Logistic Regression      : F1=0.1653, Acc=0.7605\n",
            "\n",
            "Best Classification Model: Random Forest\n",
            "\n",
            "============================================================\n",
            "CONFUSION MATRIX - Random Forest\n",
            "============================================================\n",
            "\n",
            "                Predicted\n",
            "              Low    High\n",
            "Actual Low    5018    989\n",
            "      High    1111    811\n",
            "\n",
            "============================================================\n",
            "TOP 15 IMPORTANT FEATURES - Random Forest\n",
            "============================================================\n",
            "kw_avg_avg                              : 0.0754\n",
            "kw_max_avg                              : 0.0562\n",
            "self_reference_min_shares               : 0.0373\n",
            "self_reference_avg_sharess              : 0.0367\n",
            "LDA_02                                  : 0.0358\n",
            "kw_min_avg                              : 0.0298\n",
            "timedelta                               : 0.0296\n",
            "kw_avg_max                              : 0.0287\n",
            "LDA_03                                  : 0.0284\n",
            "average_token_length                    : 0.0277\n",
            "LDA_01                                  : 0.0277\n",
            "self_reference_max_shares               : 0.0272\n",
            "global_subjectivity                     : 0.0271\n",
            "LDA_04                                  : 0.0268\n",
            "n_unique_tokens                         : 0.0265\n",
            "\n",
            "Cross-Validation F1 Scores: [0.42123171 0.41061947 0.42895442 0.41879751 0.42563567]\n",
            "Average F1 with 5-Fold CV: 0.4210 (+/- 0.0063)\n",
            "\n",
            "================================================================================\n",
            "PART 1 SUMMARY\n",
            "================================================================================\n",
            "Best Baseline Model: Random Forest\n",
            "  F1-Score:  0.4358\n",
            "  Recall:    0.4220\n",
            "  Precision: 0.4506\n",
            "  Accuracy:  0.7351\n",
            "\n",
            "\n",
            "================================================================================\n",
            "PART 2: IMBALANCE HANDLING TECHNIQUES\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "TRAINING WITH SMOTE (OVERSAMPLING)\n",
            "================================================================================\n",
            "\n",
            "Applying SMOTE...\n",
            "Original distribution: [24007  7708]\n",
            "After SMOTE: [24007 24007]\n",
            "\n",
            "Training Logistic Regression with SMOTE...\n",
            "Training Random Forest with SMOTE...\n",
            "Training Gradient Boosting with SMOTE...\n",
            "\n",
            "Logistic Regression (SMOTE)\n",
            "============================================================\n",
            "Accuracy:  0.6498\n",
            "Precision: 0.3682\n",
            "Recall:    0.6212\n",
            "F1-Score:  0.4623\n",
            "ROC-AUC:   0.6899\n",
            "\n",
            "Random Forest (SMOTE)\n",
            "============================================================\n",
            "Accuracy:  0.7515\n",
            "Precision: 0.4756\n",
            "Recall:    0.2430\n",
            "F1-Score:  0.3216\n",
            "ROC-AUC:   0.7131\n",
            "\n",
            "Gradient Boosting (SMOTE)\n",
            "============================================================\n",
            "Accuracy:  0.7625\n",
            "Precision: 0.5296\n",
            "Recall:    0.1816\n",
            "F1-Score:  0.2704\n",
            "ROC-AUC:   0.7199\n",
            "\n",
            "================================================================================\n",
            "TRAINING WITH RANDOM UNDERSAMPLING\n",
            "================================================================================\n",
            "\n",
            "Applying Random Undersampling...\n",
            "Original distribution: [24007  7708]\n",
            "After undersampling: [7708 7708]\n",
            "\n",
            "Training Random Forest with undersampling...\n",
            "\n",
            "Random Forest (Undersample)\n",
            "============================================================\n",
            "Accuracy:  0.6484\n",
            "Precision: 0.3751\n",
            "Recall:    0.6764\n",
            "F1-Score:  0.4826\n",
            "ROC-AUC:   0.7125\n",
            "\n",
            "================================================================================\n",
            "TRAINING WITH SMOTE + TOMEK LINKS\n",
            "================================================================================\n",
            "\n",
            "Applying SMOTETomek...\n",
            "Original distribution: [24007  7708]\n",
            "After SMOTETomek: [23013 23013]\n",
            "\n",
            "Training Random Forest with SMOTETomek...\n",
            "\n",
            "Random Forest (SMOTETomek)\n",
            "============================================================\n",
            "Accuracy:  0.7514\n",
            "Precision: 0.4762\n",
            "Recall:    0.2549\n",
            "F1-Score:  0.3321\n",
            "ROC-AUC:   0.7098\n",
            "\n",
            "================================================================================\n",
            "TRAINING WITH ADJUSTED CLASS WEIGHTS\n",
            "================================================================================\n",
            "\n",
            "Class weights: {0: 0.66, 1: 2.06}\n",
            "\n",
            "Training Logistic Regression with custom weights...\n",
            "Training Random Forest with custom weights...\n",
            "\n",
            "Logistic Regression (Custom Weights)\n",
            "============================================================\n",
            "Accuracy:  0.6534\n",
            "Precision: 0.3713\n",
            "Recall:    0.6197\n",
            "F1-Score:  0.4643\n",
            "ROC-AUC:   0.6905\n",
            "\n",
            "Random Forest (Custom Weights)\n",
            "============================================================\n",
            "Accuracy:  0.6933\n",
            "Precision: 0.4027\n",
            "Recall:    0.5494\n",
            "F1-Score:  0.4648\n",
            "ROC-AUC:   0.7098\n",
            "\n",
            "================================================================================\n",
            "TRAINING WITH THRESHOLD TUNING\n",
            "================================================================================\n",
            "\n",
            "============================================================\n",
            "THRESHOLD TUNING RESULTS\n",
            "============================================================\n",
            "\n",
            "Threshold: 0.30\n",
            "  F1:        0.4641\n",
            "  Precision: 0.3200\n",
            "  Recall:    0.8444\n",
            "  Accuracy:  0.5273\n",
            "\n",
            "Threshold: 0.35\n",
            "  F1:        0.4777\n",
            "  Precision: 0.3490\n",
            "  Recall:    0.7565\n",
            "  Accuracy:  0.5989\n",
            "\n",
            "Threshold: 0.40\n",
            "  F1:        0.4842\n",
            "  Precision: 0.3827\n",
            "  Recall:    0.6592\n",
            "  Accuracy:  0.6596\n",
            "\n",
            "Threshold: 0.45\n",
            "  F1:        0.4768\n",
            "  Precision: 0.4205\n",
            "  Recall:    0.5505\n",
            "  Accuracy:  0.7072\n",
            "\n",
            "Threshold: 0.50\n",
            "  F1:        0.4358\n",
            "  Precision: 0.4506\n",
            "  Recall:    0.4220\n",
            "  Accuracy:  0.7351\n",
            "\n",
            "*** Best threshold: 0.40 with F1: 0.4842 ***\n",
            "\n",
            "Confusion Matrix (threshold=0.4):\n",
            "                Predicted\n",
            "              Low    High\n",
            "Actual Low    3963   2044\n",
            "      High     655   1267\n",
            "\n",
            "================================================================================\n",
            "FINAL COMPARISON - ALL STRATEGIES\n",
            "================================================================================\n",
            "Random Forest (Threshold Tuning)        : F1=0.4842, Recall=0.6592, Precision=0.3827\n",
            "Random Forest (Undersample)             : F1=0.4826, Recall=0.6764, Precision=0.3751\n",
            "Random Forest (Custom Weights)          : F1=0.4648, Recall=0.5494, Precision=0.4027\n",
            "Logistic Regression (Custom Weights)    : F1=0.4643, Recall=0.6197, Precision=0.3713\n",
            "Logistic Regression (SMOTE)             : F1=0.4623, Recall=0.6212, Precision=0.3682\n",
            "Random Forest (SMOTETomek)              : F1=0.3321, Recall=0.2549, Precision=0.4762\n",
            "Random Forest (SMOTE)                   : F1=0.3216, Recall=0.2430, Precision=0.4756\n",
            "Gradient Boosting (SMOTE)               : F1=0.2704, Recall=0.1816, Precision=0.5296\n",
            "\n",
            "*** BEST MODEL: Random Forest (Threshold Tuning) with F1=0.4842 ***\n",
            "\n",
            "\n",
            "================================================================================\n",
            "FINAL COMPARISON: BASELINE vs IMPROVED\n",
            "================================================================================\n",
            "\n",
            "BASELINE (Random Forest):\n",
            "  F1-Score:  0.4358\n",
            "  Recall:    0.4220\n",
            "\n",
            "BEST IMPROVED (Random Forest (Threshold Tuning)):\n",
            "  F1-Score:  0.4842\n",
            "  Recall:    0.6592\n",
            "\n",
            "IMPROVEMENT:\n",
            "  F1-Score:  +11.1%\n",
            "  Recall:    +56.2%\n",
            "\n",
            "✓ Successfully improved model performance!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the best model\n",
        "import pickle\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# Determine which model to save\n",
        "if improved_f1 > baseline_f1:\n",
        "    best_overall_name = best_improved[0]\n",
        "    # Get the actual model object\n",
        "    if 'SMOTE' in best_overall_name:\n",
        "        print(f\"\\nRetraining {best_overall_name} for saving...\")\n",
        "        smote_models = train_with_smote(X_train, y_class_train)\n",
        "        best_overall_model = smote_models[best_overall_name]\n",
        "    elif 'Undersample' in best_overall_name:\n",
        "        print(f\"\\nRetraining {best_overall_name} for saving...\")\n",
        "        under_models = train_with_undersampling(X_train, y_class_train)\n",
        "        best_overall_model = under_models[best_overall_name]\n",
        "    elif 'SMOTETomek' in best_overall_name:\n",
        "        print(f\"\\nRetraining {best_overall_name} for saving...\")\n",
        "        combined_models = train_with_combined_sampling(X_train, y_class_train)\n",
        "        best_overall_model = combined_models[best_overall_name]\n",
        "    elif 'Custom Weights' in best_overall_name:\n",
        "        print(f\"\\nRetraining {best_overall_name} for saving...\")\n",
        "        weight_models = train_with_adjusted_weights(X_train, y_class_train)\n",
        "        best_overall_model = weight_models[best_overall_name]\n",
        "    else:  # Threshold Tuning\n",
        "        print(f\"\\nRetraining {best_overall_name} for saving...\")\n",
        "        threshold_models = train_with_threshold_tuning(X_train, y_class_train)\n",
        "        best_overall_model = threshold_models[best_overall_name]\n",
        "\n",
        "    print(f\"Saving improved model: {best_overall_name}\")\n",
        "else:\n",
        "    best_overall_name = results_1['best_clf_name']\n",
        "    best_overall_model = results_1['clf_models'][best_overall_name]\n",
        "    print(f\"\\nSaving baseline model: {best_overall_name}\")\n",
        "\n",
        "# Save the model to Colab session storage\n",
        "print(\"\\nSaving files...\")\n",
        "with open('best_news_shares_model.pkl', 'wb') as f:\n",
        "    pickle.dump(best_overall_model, f)\n",
        "\n",
        "# Save feature names\n",
        "with open('feature_names.pkl', 'wb') as f:\n",
        "    pickle.dump(results_1['feature_names'].tolist(), f)\n",
        "\n",
        "# Save model metadata\n",
        "model_metadata = {\n",
        "    'model_name': best_overall_name,\n",
        "    'f1_score': improved_f1 if improved_f1 > baseline_f1 else baseline_f1,\n",
        "    'recall': improved_recall if improved_f1 > baseline_f1 else baseline_recall,\n",
        "    'precision': best_improved[1]['precision'] if improved_f1 > baseline_f1 else results_1['best_clf_result']['precision'],\n",
        "    'accuracy': best_improved[1]['accuracy'] if improved_f1 > baseline_f1 else results_1['best_clf_result']['accuracy'],\n",
        "    'classification_threshold': CLASSIFICATION_THRESHOLD,\n",
        "    'feature_count': len(results_1['feature_names']),\n",
        "    'training_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "}\n",
        "\n",
        "with open('model_metadata.pkl', 'wb') as f:\n",
        "    pickle.dump(model_metadata, f)\n",
        "\n",
        "print(\"Files saved to Colab session\")\n",
        "\n",
        "# Download to your computer\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nDownloading 3 files...\")\n",
        "\n",
        "try:\n",
        "    files.download('best_news_shares_model.pkl')\n",
        "    print(\"Downloaded: best_news_shares_model.pkl\")\n",
        "except Exception as e:\n",
        "    print(f\"Error downloading model: {e}\")\n",
        "\n",
        "try:\n",
        "    files.download('feature_names.pkl')\n",
        "    print(\"Downloaded: feature_names.pkl\")\n",
        "except Exception as e:\n",
        "    print(f\"Error downloading feature names: {e}\")\n",
        "\n",
        "try:\n",
        "    files.download('model_metadata.pkl')\n",
        "    print(\"Downloaded: model_metadata.pkl\")\n",
        "except Exception as e:\n",
        "    print(f\"Error downloading metadata: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Download Complete\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nModel Details:\")\n",
        "print(f\"  Name:      {model_metadata['model_name']}\")\n",
        "print(f\"  F1-Score:  {model_metadata['f1_score']:.4f}\")\n",
        "print(f\"  Recall:    {model_metadata['recall']:.4f}\")\n",
        "print(f\"  Precision: {model_metadata['precision']:.4f}\")\n",
        "print(f\"  Accuracy:  {model_metadata['accuracy']:.4f}\")\n",
        "print(f\"  Features:  {model_metadata['feature_count']}\")\n",
        "print(f\"  Trained:   {model_metadata['training_date']}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"Finish!\")\n",
        "print(\"=\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "LBXK52LE-jSP",
        "outputId": "fc51d279-0179-4f5a-ed84-9f4f2e2f4d56"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Retraining Random Forest (Threshold Tuning) for saving...\n",
            "\n",
            "================================================================================\n",
            "TRAINING WITH THRESHOLD TUNING\n",
            "================================================================================\n",
            "Saving improved model: Random Forest (Threshold Tuning)\n",
            "\n",
            "Saving files...\n",
            "Files saved to Colab session\n",
            "\n",
            "============================================================\n",
            "============================================================\n",
            "\n",
            "Downloading 3 files...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9e72cbbc-207c-42f6-a2ef-f35a7526354d\", \"best_news_shares_model.pkl\", 23455441)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded: best_news_shares_model.pkl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1f7f94d0-99cf-44ba-b257-789295fb82aa\", \"feature_names.pkl\", 1191)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded: feature_names.pkl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a049bcc1-3d20-4ef4-8210-9952274a3534\", \"model_metadata.pkl\", 235)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded: model_metadata.pkl\n",
            "\n",
            "============================================================\n",
            "Download Complete\n",
            "============================================================\n",
            "\n",
            "Model Details:\n",
            "  Name:      Random Forest (Threshold Tuning)\n",
            "  F1-Score:  0.4842\n",
            "  Recall:    0.6592\n",
            "  Precision: 0.3827\n",
            "  Accuracy:  0.6596\n",
            "  Features:  57\n",
            "  Trained:   2025-11-02 23:58:07\n",
            "\n",
            "================================================================================\n",
            "Finish!\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ]
}